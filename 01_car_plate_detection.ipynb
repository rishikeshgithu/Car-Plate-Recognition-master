{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from weapons.Se_0a import seg_model\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    vertices: se, sw, nw, ne\n",
    "    lp_indices: indices in provinces, alphabets, and ads\n",
    "    area_ratio: in float\n",
    "    clearliness: in int, the bigger, the more clear.\n",
    "    \"\"\"\n",
    "    name = filename[:filename.index(\".\")].split('-')\n",
    "    area_ratio = float('0.'+name[0])\n",
    "    clearliness = int(name[-1])\n",
    "    lp_indices = [int(x) for x in name[-3].split('_')]\n",
    "    vertices = [tuple([int(y) for y in x.split(\"&\")]) for x in name[3].split('_')]\n",
    "    return vertices, lp_indices, area_ratio, clearliness\n",
    "\n",
    "def lp_indices2numbers(lp_indices, provinces, alphabets, ads):\n",
    "    return ''.join([provinces[lp_indices[0]]] + \\\n",
    "                   [alphabets[lp_indices[1]]] + \\\n",
    "                   [ads[x] for x in lp_indices[2:]])\n",
    "\n",
    "def build_mask(width, length, points, epsilon=1e-8):\n",
    "    lr, ll, ul, ur = points\n",
    "    result = np.ones([length, width])\n",
    "    \n",
    "    ys = np.array([np.ones(width)*x for x in range(length)])\n",
    "    xs = np.array([np.arange(width) for _ in range(length)])\n",
    "    \n",
    "    if np.abs(lr[0]-ll[0])>epsilon:\n",
    "        liney1a = (lr[1]-ll[1])/(lr[0]-ll[0])\n",
    "    else:\n",
    "        liney1a = (lr[1]-ll[1])/epsilon\n",
    "    liney1b = lr[1]-liney1a*lr[0]\n",
    "    if np.abs(ur[0]-ul[0])>epsilon:\n",
    "        liney2a = (ur[1]-ul[1])/(ur[0]-ul[0])\n",
    "    else:\n",
    "        liney2a = (ur[1]-ul[1])/epsilon\n",
    "    liney2b = ur[1]-liney2a*ur[0]\n",
    "    mask1 = (ys>(liney2a*xs+liney2b)) * (ys<(liney1a*xs+liney1b))\n",
    "    \n",
    "    if np.abs(ul[0]-ll[0])>epsilon:\n",
    "        linex1a = (ul[1]-ll[1])/(ul[0]-ll[0])\n",
    "    else:\n",
    "        linex1a = (ul[1]-ll[1])/epsilon\n",
    "    linex1b = ul[1]-linex1a*ul[0]\n",
    "    if np.abs(ur[0]-lr[0])>epsilon:\n",
    "        linex2a = (ur[1]-lr[1])/(ur[0]-lr[0])\n",
    "    else:\n",
    "        linex2a = (ur[1]-lr[1])/epsilon\n",
    "    linex2b = ur[1]-linex2a*ur[0]\n",
    "    if np.abs(linex1a)<epsilon: linex1a = epsilon\n",
    "    if np.abs(linex2a)<epsilon: linex2a = epsilon\n",
    "    mask2 = (xs>((ys-linex1b)/linex1a)) * (xs<((ys-linex2b)/linex2a))\n",
    "    \n",
    "    result*=mask1*mask2\n",
    "    result = result.astype(np.int32)\n",
    "    return result\n",
    "\n",
    "def plot_mask(img, mask):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask, cmap='gray', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def _upper_lower_bound(img, upper, lower):\n",
    "    result = (img>upper)*255+(img<upper)*img\n",
    "    result = (result<lower)*lower+(result>lower)*result\n",
    "    return result\n",
    "\n",
    "def random_aug(img, verbose = False):\n",
    "    \"\"\"\n",
    "    img as int from 0 to 255\n",
    "    \"\"\"\n",
    "    indicator1 = np.random.random()*3-1\n",
    "    result = img\n",
    "    if indicator1>1:\n",
    "        # 改contrast\n",
    "        contrast = np.random.random()+0.5\n",
    "        if verbose: print(\"contrast:\", contrast)\n",
    "        result = _upper_lower_bound(img*contrast, 254, 0).astype(int)\n",
    "    elif indicator1<0:\n",
    "        # 改brightness\n",
    "        brightness = np.random.randint(201)-100\n",
    "        if verbose: print(\"brightness:\", brightness)\n",
    "        result = _upper_lower_bound(img+brightness, 254, 0).astype(int)\n",
    "    result = result/255.0\n",
    "    \n",
    "    indicator2 = np.random.random()*3-1\n",
    "    if indicator2>1:\n",
    "        # 变糊\n",
    "        blurriness = int(np.random.randint(12))*2+3\n",
    "        if verbose: print(\"blurriness:\", blurriness)\n",
    "        result = cv2.GaussianBlur(result,(blurriness,blurriness),0)\n",
    "    elif indicator2<0:\n",
    "        # 分辨率降低\n",
    "        l = np.random.randint(193)+64\n",
    "        if verbose: print(\"image resized to (\"+str(l)+\",\"+str(l)+\")\")\n",
    "        result = cv2.resize(result, (l, l))\n",
    "    return result/max(np.max(result),1.0)\n",
    "\n",
    "def path_to_xy_segmentation(path, filename, x_shape = (512,512), y_shape = (512,512),\n",
    "                            verbose = False, augmentation = True):\n",
    "    img = cv2.imread(path+filename)\n",
    "    img = np.dot(img,np.array([[0,0,1],[0,1,0],[1,0,0]]))\n",
    "    if augmentation:\n",
    "        x = random_aug(img)\n",
    "        x = cv2.resize(x, x_shape)\n",
    "    else:\n",
    "        x = cv2.resize(img/255.1, x_shape)\n",
    "    vertices, lp_indices, area_ratio, clearliness = parse_filename(filename)\n",
    "    mask = build_mask(img.shape[1], img.shape[0], vertices)/1.0\n",
    "    y = cv2.resize(mask, y_shape)\n",
    "    if verbose: plot_mask(x, y)\n",
    "    return x,y\n",
    "\n",
    "def get_batch(file_dict, batch_size,\n",
    "              x_shape = (512,512), y_shape = (512,512), augmentation = True):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    folders = list(file_dict.keys())\n",
    "    for _ in range(batch_size):\n",
    "        folder = np.random.choice(folders)\n",
    "        filename = np.random.choice(file_dict[folder])\n",
    "        x,y = path_to_xy_segmentation(folder, filename,x_shape = x_shape, y_shape = y_shape,\n",
    "                                      augmentation = augmentation)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def seg_to_vertices(img, use_dilated = False, verbose = False):\n",
    "    if verbose:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    if use_dilated:\n",
    "        # dilate thresholded image - merges top/bottom \n",
    "        kernel = np.ones((3,3))\n",
    "        dilated = cv2.dilate(img, kernel, iterations=3)\n",
    "        if verbose:\n",
    "            plt.imshow(dilated)\n",
    "            plt.show()\n",
    "        current_img = dilated\n",
    "    else:\n",
    "        current_img = img\n",
    "\n",
    "    # find contours\n",
    "    contours, hierarchy = cv2.findContours(current_img.astype(np.uint8),\n",
    "                                           cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if verbose: print(\"largest contour has \",len(contours[0]),\"points\")\n",
    "    if len(contours)<=0 or len(contours[0])<4:\n",
    "        if verbose: print(\"No result\")\n",
    "        return []\n",
    "    \n",
    "    # simplify contours\n",
    "    used_index = set([])\n",
    "    index = 0.01\n",
    "    step = 2\n",
    "    while(len(used_index)<10):\n",
    "        epsilon = index*cv2.arcLength(contours[0],True)\n",
    "        approx = cv2.approxPolyDP(contours[0],epsilon,True)\n",
    "        if verbose: print(\"index =\", index, \", # points =\", len(approx))\n",
    "        if len(approx)==4:\n",
    "            break\n",
    "        elif len(approx)>4:\n",
    "            if (index*step) in used_index:\n",
    "                step = 1+(step-1)/2\n",
    "                used_index.add(index*step)\n",
    "                index*=step\n",
    "            else:\n",
    "                used_index.add(index*step)\n",
    "                index*=step\n",
    "        else:\n",
    "            if (index/step) in used_index:\n",
    "                step = 1+(step-1)/2\n",
    "                used_index.add(index/step)\n",
    "                index/=step\n",
    "            else:\n",
    "                used_index.add(index/step)\n",
    "                index/=step\n",
    "    if len(approx)!=4:\n",
    "        if verbose: print(\"No result\")\n",
    "        return []\n",
    "    if verbose:\n",
    "        cv2.drawContours(img, [approx], 0, (255,255,255), 3)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    return approx\n",
    "\n",
    "def _bound(value, upper, lower):\n",
    "    return min(max(value, lower), upper)\n",
    "\n",
    "def rearange_vertices(vertices, img_shape):\n",
    "    sorted_vertices_y = sorted(vertices, key=lambda x: x[0,1])\n",
    "    sorted_vertices_x = sorted(vertices, key=lambda x: x[0,0])\n",
    "    mid_y = (sorted_vertices_y[2][0][1]-sorted_vertices_y[1][0][1])\n",
    "    max_y = (sorted_vertices_y[3][0][1]-sorted_vertices_y[0][0][1])\n",
    "    mid_x = (sorted_vertices_x[2][0][0]-sorted_vertices_x[1][0][0])\n",
    "    max_x = (sorted_vertices_x[3][0][0]-sorted_vertices_x[0][0][0])\n",
    "    \n",
    "    if (mid_y/max_y) > (mid_x/max_x):\n",
    "        sorted_vertices = sorted_vertices_y\n",
    "        if sorted_vertices[0][0][0]<sorted_vertices[1][0][0]:\n",
    "            nw = sorted_vertices[0][0]\n",
    "            ne = sorted_vertices[1][0]\n",
    "        else:\n",
    "            nw = sorted_vertices[1][0]\n",
    "            ne = sorted_vertices[0][0]\n",
    "        if sorted_vertices[2][0][0]<sorted_vertices[3][0][0]:\n",
    "            sw = sorted_vertices[2][0]\n",
    "            se = sorted_vertices[3][0]\n",
    "        else:\n",
    "            sw = sorted_vertices[3][0]\n",
    "            se = sorted_vertices[2][0]\n",
    "    else:\n",
    "        sorted_vertices = sorted_vertices_x\n",
    "        if sorted_vertices[0][0][1]<sorted_vertices[1][0][1]:\n",
    "            nw = sorted_vertices[0][0]\n",
    "            sw = sorted_vertices[1][0]\n",
    "        else:\n",
    "            nw = sorted_vertices[1][0]\n",
    "            sw = sorted_vertices[0][0]\n",
    "        if sorted_vertices[2][0][1]<sorted_vertices[3][0][1]:\n",
    "            ne = sorted_vertices[2][0]\n",
    "            se = sorted_vertices[3][0]\n",
    "        else:\n",
    "            ne = sorted_vertices[3][0]\n",
    "            se = sorted_vertices[2][0]\n",
    "    diagonal_length = ((se[0]-nw[0])**2+(se[1]-nw[1])**2)**0.5\n",
    "    diagonal_length+= ((ne[0]-sw[0])**2+(ne[1]-sw[1])**2)**0.5\n",
    "    diagonal_length/= 2\n",
    "    extension = diagonal_length*0.05\n",
    "    \n",
    "    ####################################\n",
    "    # 真正输出的时候不要加这个 extension\n",
    "    # 让 recognition 算法自己来添加该部分\n",
    "    ####################################\n",
    "    \n",
    "    return [(_bound(se[0]+extension, img_shape[0], 0), _bound(se[1]+extension, img_shape[1], 0)),\n",
    "            (_bound(sw[0]-extension, img_shape[0], 0), _bound(sw[1]+extension, img_shape[1], 0)),\n",
    "            (_bound(nw[0]-extension, img_shape[0], 0), _bound(nw[1]-extension, img_shape[1], 0)),\n",
    "            (_bound(ne[0]+extension, img_shape[0], 0), _bound(ne[1]-extension, img_shape[1], 0)),]\n",
    "\n",
    "def crop_out_plate(img, vertices):\n",
    "    pts1 = np.float32(vertices)\n",
    "    pts2 = np.float32([[300,150],[0,150],[0,0],[300,0]])\n",
    "    M=cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    return cv2.warpPerspective(np.uint8(img),M,(300,150))\n",
    "\n",
    "file_dict = {}\n",
    "training_dict = {}\n",
    "test_dict = {}\n",
    "# folders = [\"CCPD2019/ccpd_base/\", \"CCPD2019/ccpd_blur/\", \"CCPD2019/ccpd_challenge/\",\n",
    "#            \"CCPD2019/ccpd_db/\", \"CCPD2019/ccpd_fn/\",\n",
    "#            \"CCPD2019/ccpd_rotate/\", \"CCPD2019/ccpd_tilt/\", \"CCPD2019/ccpd_weather/\"]\n",
    "folders = [\"CCPD2019/ccpd_base/\"]\n",
    "for folder in folders:\n",
    "    file_dict[folder] = [x for x in os.listdir(folder) if x[0]!='.']\n",
    "    split_point = int(len(file_dict[folder])/20)\n",
    "    training_dict[folder] = file_dict[folder][:-split_point]\n",
    "    test_dict[folder] = file_dict[folder][-split_point:]\n",
    "\n",
    "xs, ys = get_batch(file_dict, 10, x_shape = (512,512), y_shape = (64,64))\n",
    "print(xs.shape, ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "n_batch = 2000\n",
    "learning_rate = 2e-4\n",
    "saving_period = 100\n",
    "model_name = \"Se_0a_1\"\n",
    "if model_name not in os.listdir('models/'):\n",
    "    os.mkdir('models/'+model_name)\n",
    "x_shape = (512,512)\n",
    "y_shape = (64,64)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = seg_model()\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,\n",
    "                                      allow_soft_placement=True,\n",
    "                                      log_device_placement=False)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"models/Se_0a_1/Se_0a_1_0.ckpt\")\n",
    "    # tensorboard --logdir logs/\n",
    "    # summary_writer = tf.summary.FileWriter(logdir = \"logs\", graph = tf.get_default_graph())\n",
    "    xs, ys = get_batch(file_dict, 1, x_shape = x_shape, y_shape = y_shape)\n",
    "    prediction = model.predict(sess, xs)\n",
    "    show_result(xs, ys, prediction)\n",
    "\n",
    "    for i in range(1, 1+n_batch):\n",
    "        bn_momentum = min(0.7, (1-10/(i+10)))\n",
    "        xs, ys = get_batch(training_dict, BATCH_SIZE, x_shape = (512,512), y_shape = (64,64))\n",
    "        loss, pred, summary = model.train(sess, learning_rate, bn_momentum, xs, ys)\n",
    "        # summary_writer.add_summary(summary, i)\n",
    "        if i%10 == 0:\n",
    "            print(i, loss)\n",
    "        \n",
    "        if i%saving_period == 0:\n",
    "            save_path = saver.save(sess, \"models/\"+model_name+\"/\"+model_name+\"_\"+str(int(i/10000))+\".ckpt\")\n",
    "            print(\"Model saved in path: \"+save_path)\n",
    "            xs, ys = get_batch(test_dict, BATCH_SIZE, x_shape = (512,512), y_shape = (64,64))\n",
    "            prediction = model.predict(sess, xs)\n",
    "            show_result(xs, ys, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37_torch] *",
   "language": "python",
   "name": "conda-env-py37_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
